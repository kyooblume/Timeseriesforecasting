import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.feature_selection import RFECV
from sklearn.model_selection import TimeSeriesSplit
import optuna
import time  # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ç”¨

# Streamlit ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ“Š æ™‚ç³»åˆ—äºˆæ¸¬")

# ãƒ‡ãƒ¼ã‚¿ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–ï¼ˆåˆå›èµ·å‹•æ™‚ï¼‰
if "df" not in st.session_state:
    st.session_state["df"] = None

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ•ã‚§ãƒ¼ã‚ºé¸æŠã®ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
phase = st.sidebar.selectbox("ãƒ•ã‚§ãƒ¼ã‚ºã‚’é¸æŠã—ã¦ãã ã•ã„", ["1.ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "2.ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›´", "3.åˆ†æ"])

if phase == "1.ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.write("### ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "xlsx", "txt", "json"])

    if uploaded_file is not None:
        file_extension = uploaded_file.name.split(".")[-1]

        try:
            if file_extension == "csv":
                df = pd.read_csv(uploaded_file, encoding="utf-8-sig")
            elif file_extension == "xlsx":
                xls = pd.ExcelFile(uploaded_file)
                sheet_name = st.selectbox("ã‚·ãƒ¼ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„", xls.sheet_names)
                df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
            elif file_extension == "txt":
                delimiter = st.selectbox("åŒºåˆ‡ã‚Šæ–‡å­—ã‚’é¸æŠã—ã¦ãã ã•ã„", ["\t", " "])
                df = pd.read_csv(uploaded_file, delimiter=delimiter, encoding="utf-8-sig")
            elif file_extension == "json":
                df = pd.read_json(uploaded_file)
            else:
                st.error("å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
                st.stop()

            # èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state["df"] = df
            st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿æˆåŠŸï¼")
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

elif phase == "2.ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›´":
    st.subheader("ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›´")
    st.write("åŸºæœ¬çš„ã«ã¯ç„¡è¦–ã—ã¦ãã ã•ã„")
    df = st.session_state.get("df")

    if df is not None:
        for column in df.columns:
            dtype = st.selectbox(f"{column} ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’é¸æŠã—ã¦ãã ã•ã„", ["è‡ªå‹•æ¤œå‡º", "æ•´æ•°", "æµ®å‹•å°æ•°ç‚¹æ•°", "æ–‡å­—åˆ—", "æ—¥ä»˜", "ãƒã‚¤ãƒŠãƒª"], key=column)
            if dtype == "æ•´æ•°":
                df[column] = pd.to_numeric(df[column], errors="coerce").astype("Int64")
            elif dtype == "æµ®å‹•å°æ•°ç‚¹æ•°":
                df[column] = pd.to_numeric(df[column], errors="coerce")
            elif dtype == "æ–‡å­—åˆ—":
                df[column] = df[column].astype(str)
            elif dtype == "æ—¥ä»˜":
                df[column] = pd.to_datetime(df[column], errors="coerce")
            elif dtype == "ãƒã‚¤ãƒŠãƒª":
                df[column] = df[column].astype("bool")

        # å¤‰æ›´å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        st.session_state["df"] = df
    else:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã¯1ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

elif phase == "3.åˆ†æ":
    df = st.session_state.get("df")

    if df is not None:
        numerical_df = df.select_dtypes(include=["number"])
        if not numerical_df.empty:
            selected_variable = st.selectbox("ğŸ“Œ ç›¸é–¢ã‚’èª¿ã¹ã‚‹å¤‰æ•°ã‚’é¸æŠ", numerical_df.columns.tolist())

            if selected_variable:
                correlation_matrix = numerical_df.corr()
                correlation_series = correlation_matrix[selected_variable].drop(selected_variable).sort_values(ascending=False)
                top_positive = correlation_series.head(5)
                top_negative = correlation_series.tail(5)

                st.subheader(f"ğŸ“Š {selected_variable} ã¨ç›¸é–¢ãŒé«˜ã„ãƒ»ä½ã„å¤‰æ•°")
                col1, col2 = st.columns(2)
                with col1:
                    st.write("ğŸ”µ **æ­£ã®ç›¸é–¢ãŒé«˜ã„5ã¤**")
                    st.dataframe(top_positive)
                with col2:
                    st.write("ğŸ”´ **è² ã®ç›¸é–¢ãŒé«˜ã„5ã¤**")
                    st.dataframe(top_negative)

                # å¯è¦–åŒ–
                fig, ax = plt.subplots(figsize=(10, 5))
                colors = ["blue"] * 5 + ["red"] * 5
                top_features = pd.concat([top_positive, top_negative])
                ax.barh(top_features.index[::-1], top_features.values[::-1], color=colors[::-1])
                ax.set_xlabel("Correlation Coefficient")
                ax.set_title(f"Top 5 Positive & Negative Correlations with {selected_variable}")
                ax.axvline(x=0, color="black", linewidth=1)
                st.pyplot(fig)

        if "yyyymmdd" in df.columns:
            df["yyyymmdd"] = pd.to_datetime(df["yyyymmdd"], errors="coerce")
            df = df.dropna(subset=["yyyymmdd"])
            min_date, max_date = df["yyyymmdd"].min(), df["yyyymmdd"].max()

            st.subheader("ğŸ“ˆ æ™‚ç³»åˆ—äºˆæ¸¬")

            train_start, train_end = st.date_input("ğŸ“… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“", value=(min_date, max_date - pd.DateOffset(months=1)), min_value=min_date, max_value=max_date)
            test_start, test_end = st.date_input("ğŸ“… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœŸé–“", value=(max_date - pd.DateOffset(months=1), max_date), min_value=min_date, max_value=max_date)

            df_train = df[(df["yyyymmdd"] >= pd.to_datetime(train_start)) & (df["yyyymmdd"] <= pd.to_datetime(train_end))].copy()
            df_test = df[(df["yyyymmdd"] >= pd.to_datetime(test_start)) & (df["yyyymmdd"] <= pd.to_datetime(test_end))].copy()

            selected_variable = st.selectbox("ğŸ“Œ äºˆæ¸¬ã™ã‚‹å¤‰æ•°ã‚’é¸æŠ", df_train.select_dtypes(include=["number"]).columns.tolist())
            frequency = st.selectbox("ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã‚’é¸æŠã—ã¦ãã ã•ã„", ["æ—¥æ¬¡", "æœˆæ¬¡", "å¹´æ¬¡"])
            freq_map = {"æ—¥æ¬¡": "D", "æœˆæ¬¡": "M", "å¹´æ¬¡": "Y"}
            freq = freq_map.get(frequency, None)
            # ğŸ“Œ ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¨­å®š
            progress_bar = st.progress(0)
            status_text = st.empty()
            # ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã«å¿œã˜ãŸç‰¹å¾´é‡ã‚’ä½œæˆã™ã‚‹é–¢æ•°
            def create_time_features(df, selected_variable=None, freq=None):
                """æ—¥æ¬¡ã€æœˆæ¬¡ã¾ãŸã¯å¹´æ¬¡ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã‚’ä½œæˆ"""
                df["year"] = df["yyyymmdd"].dt.year
                if freq == "D":  # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿
                    df["month"] = df["yyyymmdd"].dt.month
                    df["day"] = df["yyyymmdd"].dt.day
                    df["dayofweek"] = df["yyyymmdd"].dt.dayofweek
                    if selected_variable is not None and selected_variable in df.columns:
                        df["lag_1"] = df[selected_variable].shift(1)
                        df["lag_7"] = df[selected_variable].shift(7)
                        df["ma_7"] = df[selected_variable].rolling(window=7).mean()
                        df["ma_30"] = df[selected_variable].rolling(window=30).mean()
                elif freq == "M":  # æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿
                    df["month"] = df["yyyymmdd"].dt.month
                    df["quarter"] = df["yyyymmdd"].dt.quarter
                    if selected_variable is not None and selected_variable in df.columns:
                        df["lag_1"] = df[selected_variable].shift(1)
                        df["lag_3"] = df[selected_variable].shift(3)
                        df["lag_6"] = df[selected_variable].shift(6)
                        df["lag_12"] = df[selected_variable].shift(12)
                        df["ma_3"] = df[selected_variable].rolling(window=3).mean()
                        df["ma_6"] = df[selected_variable].rolling(window=6).mean()
                        df["ma_12"] = df[selected_variable].rolling(window=12).mean()
                        df["yoy_change"] = df[selected_variable] / df["lag_12"] - 1  # å‰å¹´åŒæœˆæ¯”
                elif freq == "Y":  # å¹´æ¬¡ãƒ‡ãƒ¼ã‚¿
                    if selected_variable is not None and selected_variable in df.columns:
                        df["lag_1"] = df[selected_variable].shift(1)
                        df["lag_2"] = df[selected_variable].shift(2)
                        df["lag_5"] = df[selected_variable].shift(5)
                        df["lag_10"] = df[selected_variable].shift(10)
                        df["ma_2"] = df[selected_variable].rolling(window=2).mean()
                        df["ma_5"] = df[selected_variable].rolling(window=5).mean()
                        df["ma_10"] = df[selected_variable].rolling(window=10).mean()
                        df["growth_rate"] = df[selected_variable] / df["lag_1"] - 1  # å‰å¹´æ¯”
                return df.dropna()

            # ç‰¹å¾´é‡ã‚’ä½œæˆ
            df_train = create_time_features(df_train.copy(), selected_variable, freq)
            df_test = create_time_features(df_test.copy(), selected_variable, freq)

            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            df_train = pd.get_dummies(df_train)
            df_test = pd.get_dummies(df_test)

            # ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®å®šç¾©ï¼ˆæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ï¼‰
            X_train = df_train.select_dtypes(include=[np.number]).drop(columns=[selected_variable])
            y_train = df_train[selected_variable]
            X_test = df_test.select_dtypes(include=[np.number]).drop(columns=[selected_variable])
            y_test = df_test[selected_variable]

            # æ¬ æå€¤ã‚’é™¤å»
            X_train = X_train.dropna()
            y_train = y_train.loc[X_train.index]  # X_trainã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã•ã›ã‚‹

            X_test = X_test.dropna()
            y_test = y_test.loc[X_test.index]

            # ç‰¹å¾´é‡é¸æŠ (RFECV)
            rfecv = RFECV(
                estimator=xgb.XGBRegressor(random_state=100),
                min_features_to_select=5,
                step=1,
                scoring="neg_mean_absolute_percentage_error"
            )
            rfecv.fit(X_train, y_train)

            selected_features = X_train.columns[rfecv.support_].tolist()
            st.write("é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡:", selected_features)

            # ç‰¹å¾´é‡é¸æŠå¾Œã®ãƒ‡ãƒ¼ã‚¿
            X_train = X_train[selected_features]
            X_test = X_test[selected_features]

            # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­å®š
            tscv = TimeSeriesSplit(n_splits=5)

            # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆOptunaï¼‰
            def objective(trial):
                params = {
                    'n_estimators': trial.suggest_int('n_estimators', 50, 500),
                    'max_depth': trial.suggest_int('max_depth', 2, 10),
                    'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),
                    'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),
                    'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),
                    'gamma': trial.suggest_float('gamma', 0, 5),
                    'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),
                    'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),
                    'random_state': 100
                }

                mape_scores = []

                for train_index, val_index in tscv.split(X_train):
                    X_train_cv, X_val_cv = X_train.iloc[train_index], X_train.iloc[val_index]
                    y_train_cv, y_val_cv = y_train.iloc[train_index], y_train.iloc[val_index]

                    model = xgb.XGBRegressor(**params)
                    model.fit(X_train_cv, y_train_cv)
                    y_val_pred = model.predict(X_val_cv)
                    mape_score = mean_absolute_percentage_error(y_val_cv, y_val_pred)
                    mape_scores.append(mape_score)

                return np.mean(mape_scores)

            study = optuna.create_study(direction='minimize')
            study.optimize(objective, n_trials=50)

            # æœ€é©ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’
            best_params = study.best_params
            st.write("æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:", best_params)

            model = xgb.XGBRegressor(**best_params)
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            st.subheader(f"ğŸ“ˆ {selected_variable} ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æœŸé–“ã®äºˆå®Ÿãƒ—ãƒ­ãƒƒãƒˆ")
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(df_test["yyyymmdd"], y_test, label="Actual", marker="o")
            ax.plot(df_test["yyyymmdd"], y_pred, label="Predicted", marker="x")
            plt.xticks(rotation=45)
            plt.legend()
            st.pyplot(fig)

            # MAPE ã®è¨ˆç®—
            mape = mean_absolute_percentage_error(y_test, y_pred)
            st.write(f"âœ… **MAPE**: {mape:.2f} %")

            # ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã«åŸºã¥ã„ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®äºˆæ¸¬æœŸé–“ã‚’è¨­å®š
            freq_map = {"æ—¥æ¬¡": "D", "æœˆæ¬¡": "M", "å¹´æ¬¡": "Y"}
            freq = freq_map.get(frequency, None)

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®äºˆæ¸¬æœŸé–“ã‚’è¨­å®š
            default_future_periods = {"D": 30, "M": 12, "Y": 5}  # æ—¥æ¬¡: 30æ—¥, æœˆæ¬¡: 12ãƒ¶æœˆ, å¹´æ¬¡: 5å¹´
            future_periods = default_future_periods.get(freq, 12)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœˆæ¬¡ã®12ãƒ¶æœˆ

            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦æœªæ¥ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢ã™ã‚‹é–¢æ•°
            def align_features(X_train, future_df):
                """
                è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã«åˆã‚ã›ã¦æœªæ¥ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢ã™ã‚‹
                """
                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„ç‰¹å¾´é‡ã‚’æœªæ¥ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤
                future_df = future_df[X_train.columns.intersection(future_df.columns)]

                # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ãŒæœªæ¥ãƒ‡ãƒ¼ã‚¿ã«ãªã„ç‰¹å¾´é‡ã‚’è¿½åŠ 
                for col in X_train.columns:
                    if col not in future_df.columns:
                        future_df[col] = 0  # æ¬ æå€¤ã‚’ 0 ã§åŸ‹ã‚ã‚‹

                # åˆ—é †ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«æƒãˆã‚‹
                future_df = future_df[X_train.columns]

                return future_df

            # æœªæ¥äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
            future_periods = {"D": 30, "M": 12, "Y": 5}
            future_dates = pd.date_range(start=max_date + pd.DateOffset(1), periods=future_periods[freq], freq=freq)
            future_df = pd.DataFrame({"yyyymmdd": future_dates})

            # ç‰¹å¾´é‡ã‚’ä½œæˆ
            future_df = create_time_features(future_df, selected_variable, freq)

            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦æœªæ¥ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
            future_df = align_features(X_train, future_df)

            # äºˆæ¸¬å®Ÿæ–½
            future_pred = model.predict(future_df)

            # äºˆæ¸¬çµæœã®å¯è¦–åŒ–
            st.subheader(f"ğŸ“ˆ {selected_variable} ã®æœªæ¥äºˆæ¸¬")
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(future_dates, future_pred, label="Forecast", marker="x")  # äºˆæ¸¬å€¤ã®ã¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
            plt.xticks(rotation=45)
            plt.legend()
            st.pyplot(fig)

            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
            st.download_button(
                label="ğŸ“¥ äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=pd.DataFrame({"yyyymmdd": future_dates, "Predicted": future_pred}).to_csv(index=False).encode("utf-8"),
                file_name="forecast_results.csv",
                mime="text/csv",
            )

            # çµæœã‚’è¡¨ç¤º
            st.subheader("ğŸ“ˆ äºˆæ¸¬çµæœ")
            st.write(pd.DataFrame({"yyyymmdd": future_dates, "Predicted": future_pred}))

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "show_qa" not in st.session_state:
    st.session_state["show_qa"] = False  # åˆæœŸå€¤ã‚’ False ã«è¨­å®š

with st.sidebar:
    if st.button("Q&A"):
        st.session_state["show_qa"] = not st.session_state["show_qa"]

    # Q&Aã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤ºï¼ˆãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã ã‘ï¼‰
    if st.session_state["show_qa"]:
        st.write("### ã‚ˆãã‚ã‚‹è³ªå•")
        st.write("**Q1: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“ã®ç›®å®‰ã¯ï¼Ÿ**")
        st.write("A1: æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆæœ€ä½ã§ã‚‚ 3å¹´åˆ†ã€å¹´æ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯æœ€ä½ã§ã‚‚ 20å¹´åˆ†ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        
        st.write("**Q2: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¿˜ã‚ŒãŸå ´åˆã¯ï¼Ÿ**")
        st.write("A2: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¿˜ã‚ŒãŸå ´åˆã¯ã€ãƒ­ã‚°ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ã€Œãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¿˜ã‚ŒãŸã€ãƒªãƒ³ã‚¯ã‹ã‚‰å†è¨­å®šã§ãã¾ã™ã€‚")
        
        st.write("**Q3: ãŠå•ã„åˆã‚ã›æ–¹æ³•ã¯ï¼Ÿ**")
        st.write("A3: æ“ä½œæ–¹æ³•ãŒã‚ã‹ã‚‰ãªã„ã€æ­£ã—ãæ“ä½œã—ã¦ã„ã‚‹ã¯ãšãªã®ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã€ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ãŒã©ã†ã—ã¦ã‚‚å‡ºãªã„ãªã©ã€è³ªå•ãƒ»ã”ç›¸è«‡ãŒã‚ã‚‹æ–¹ã¯ä»¥ä¸‹é€£çµ¡å…ˆã«çŠ¶æ³ã‚’ã”é€£çµ¡ãã ã•ã„ã€‚æ‹…å½“è€…ã‚ˆã‚Šè¿”ä¿¡ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚<br>å•ã„åˆã‚ã›å…ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼šcontact@b-mystory.com<br>æ‹…å½“ï¼šä½œç”°ã€é‡æœ¬", unsafe_allow_html=True)

