import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.feature_selection import RFECV
from sklearn.model_selection import TimeSeriesSplit
import optuna
import time  # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ç”¨
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Streamlit ã‚¢ãƒ—ãƒªã®ã‚¿ã‚¤ãƒˆãƒ«
st.title("ğŸ“Š æ™‚ç³»åˆ—äºˆæ¸¬")

# ãƒ‡ãƒ¼ã‚¿ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–ï¼ˆåˆå›èµ·å‹•æ™‚ï¼‰
if "df" not in st.session_state:
    st.session_state["df"] = None

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ•ã‚§ãƒ¼ã‚ºé¸æŠã®ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
phase = st.sidebar.selectbox("ãƒ•ã‚§ãƒ¼ã‚ºã‚’é¸æŠã—ã¦ãã ã•ã„", ["1.ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "2.ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›´", "3.åˆ†æ"])

if phase == "1.ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    st.write("### ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    uploaded_file = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv", "xlsx", "txt", "json"])

    if uploaded_file is not None:
        file_extension = uploaded_file.name.split(".")[-1]

        try:
            if file_extension == "csv":
                df = pd.read_csv(uploaded_file, encoding="utf-8-sig")
            elif file_extension == "xlsx":
                xls = pd.ExcelFile(uploaded_file)
                sheet_name = st.selectbox("ã‚·ãƒ¼ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„", xls.sheet_names)
                df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
            elif file_extension == "txt":
                delimiter = st.selectbox("åŒºåˆ‡ã‚Šæ–‡å­—ã‚’é¸æŠã—ã¦ãã ã•ã„", ["\t", " "])
                df = pd.read_csv(uploaded_file, delimiter=delimiter, encoding="utf-8-sig")
            elif file_extension == "json":
                df = pd.read_json(uploaded_file)
            else:
                st.error("å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚")
                st.stop()

            # èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state["df"] = df
            st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿æˆåŠŸï¼")
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

elif phase == "2.ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›´":
    st.subheader("ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›´")
    st.write("åŸºæœ¬çš„ã«ã¯ç„¡è¦–ã—ã¦ãã ã•ã„")
    df = st.session_state.get("df")

    if df is not None:
        for column in df.columns:
            dtype = st.selectbox(f"{column} ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’é¸æŠã—ã¦ãã ã•ã„", ["è‡ªå‹•æ¤œå‡º", "æ•´æ•°", "æµ®å‹•å°æ•°ç‚¹æ•°", "æ–‡å­—åˆ—", "æ—¥ä»˜", "ãƒã‚¤ãƒŠãƒª"], key=column)
            if dtype == "æ•´æ•°":
                df[column] = pd.to_numeric(df[column], errors="coerce").astype("Int64")
            elif dtype == "æµ®å‹•å°æ•°ç‚¹æ•°":
                df[column] = pd.to_numeric(df[column], errors="coerce")
            elif dtype == "æ–‡å­—åˆ—":
                df[column] = df[column].astype(str)
            elif dtype == "æ—¥ä»˜":
                df[column] = pd.to_datetime(df[column], errors="coerce")
            elif dtype == "ãƒã‚¤ãƒŠãƒª":
                df[column] = df[column].astype("bool")

        # å¤‰æ›´å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        st.session_state["df"] = df
    else:
        st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšã¯1ã§ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

elif phase == "3.åˆ†æ":
    df = st.session_state.get("df")

    if df is not None:
        numerical_df = df.select_dtypes(include=["number"])
        if not numerical_df.empty:
            selected_variable = st.selectbox("ğŸ“Œ ç›¸é–¢ã‚’èª¿ã¹ã‚‹å¤‰æ•°ã‚’é¸æŠ", numerical_df.columns.tolist())

            if selected_variable:
                correlation_matrix = numerical_df.corr()
                correlation_series = correlation_matrix[selected_variable].drop(selected_variable).sort_values(ascending=False)
                top_positive = correlation_series.head(5)
                top_negative = correlation_series.tail(5)

                st.subheader(f"ğŸ“Š {selected_variable} ã¨ç›¸é–¢ãŒé«˜ã„ãƒ»ä½ã„å¤‰æ•°")
                col1, col2 = st.columns(2)
                with col1:
                    st.write("ğŸ”µ **æ­£ã®ç›¸é–¢ãŒé«˜ã„5ã¤**")
                    st.dataframe(top_positive)
                with col2:
                    st.write("ğŸ”´ **è² ã®ç›¸é–¢ãŒé«˜ã„5ã¤**")
                    st.dataframe(top_negative)

                # å¯è¦–åŒ–
                fig, ax = plt.subplots(figsize=(10, 5))
                colors = ["blue"] * 5 + ["red"] * 5
                top_features = pd.concat([top_positive, top_negative])
                ax.barh(top_features.index[::-1], top_features.values[::-1], color=colors[::-1])
                ax.set_xlabel("Correlation Coefficient")
                ax.set_title(f"Top 5 Positive & Negative Correlations with {selected_variable}")
                ax.axvline(x=0, color="black", linewidth=1)
                st.pyplot(fig)

        if "yyyymmdd" in df.columns:
            df["yyyymmdd"] = pd.to_datetime(df["yyyymmdd"], errors="coerce")
            df = df.dropna(subset=["yyyymmdd"])
            min_date, max_date = df["yyyymmdd"].min(), df["yyyymmdd"].max()

            st.subheader("ğŸ“ˆ æ™‚ç³»åˆ—äºˆæ¸¬")

            train_start, train_end = st.date_input("ğŸ“… ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“", value=(min_date, max_date - pd.DateOffset(months=1)), min_value=min_date, max_value=max_date)
            test_start, test_end = st.date_input("ğŸ“… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœŸé–“", value=(max_date - pd.DateOffset(months=1), max_date), min_value=min_date, max_value=max_date)

            df_train = df[(df["yyyymmdd"] >= pd.to_datetime(train_start)) & (df["yyyymmdd"] <= pd.to_datetime(train_end))].copy()
            df_test = df[(df["yyyymmdd"] >= pd.to_datetime(test_start)) & (df["yyyymmdd"] <= pd.to_datetime(test_end))].copy()

            selected_variable = st.selectbox("ğŸ“Œ äºˆæ¸¬ã™ã‚‹å¤‰æ•°ã‚’é¸æŠ", df_train.select_dtypes(include=["number"]).columns.tolist())
            frequency = st.selectbox("ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã‚’é¸æŠã—ã¦ãã ã•ã„", ["æ—¥æ¬¡", "æœˆæ¬¡", "å¹´æ¬¡"])
            freq_map = {"æ—¥æ¬¡": "D", "æœˆæ¬¡": "M", "å¹´æ¬¡": "Y"}
            freq = freq_map.get(frequency, None)


            # ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã«å¿œã˜ãŸç‰¹å¾´é‡ã‚’ä½œæˆã™ã‚‹é–¢æ•°
            def create_time_features(df, selected_variable=None, freq=None):
                """æ—¥æ¬¡ã€æœˆæ¬¡ã¾ãŸã¯å¹´æ¬¡ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã‚’ä½œæˆ"""
                df["year"] = df["yyyymmdd"].dt.year
                if freq == "D":  # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿
                    df["month"] = df["yyyymmdd"].dt.month
                    df["day"] = df["yyyymmdd"].dt.day
                    df["dayofweek"] = df["yyyymmdd"].dt.dayofweek
                    if selected_variable is not None and selected_variable in df.columns:
                        df["lag_1"] = df[selected_variable].shift(1)
                        df["lag_7"] = df[selected_variable].shift(7)
                        df["ma_7"] = df[selected_variable].rolling(window=7).mean()
                        df["ma_30"] = df[selected_variable].rolling(window=30).mean()
                elif freq == "M":  # æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿
                    df["month"] = df["yyyymmdd"].dt.month
                    df["quarter"] = df["yyyymmdd"].dt.quarter
                    if selected_variable is not None and selected_variable in df.columns:
                        df["lag_1"] = df[selected_variable].shift(1)
                        df["lag_3"] = df[selected_variable].shift(3)
                        df["lag_6"] = df[selected_variable].shift(6)
                        df["lag_12"] = df[selected_variable].shift(12)
                        df["ma_3"] = df[selected_variable].rolling(window=3).mean()
                        df["ma_6"] = df[selected_variable].rolling(window=6).mean()
                        df["ma_12"] = df[selected_variable].rolling(window=12).mean()
                        df["yoy_change"] = df[selected_variable] / df["lag_12"] - 1  # å‰å¹´åŒæœˆæ¯”
                elif freq == "Y":  # å¹´æ¬¡ãƒ‡ãƒ¼ã‚¿
                    if selected_variable is not None and selected_variable in df.columns:
                        df["lag_1"] = df[selected_variable].shift(1)
                        df["lag_2"] = df[selected_variable].shift(2)
                        df["lag_5"] = df[selected_variable].shift(5)
                        df["lag_10"] = df[selected_variable].shift(10)
                        df["ma_2"] = df[selected_variable].rolling(window=2).mean()
                        df["ma_5"] = df[selected_variable].rolling(window=5).mean()
                        df["ma_10"] = df[selected_variable].rolling(window=10).mean()
                        df["growth_rate"] = df[selected_variable] / df["lag_1"] - 1  # å‰å¹´æ¯”
                return df.dropna()

            # ç‰¹å¾´é‡ã‚’ä½œæˆ
            df_train = create_time_features(df_train.copy(), selected_variable, freq)
            df_test = create_time_features(df_test.copy(), selected_variable, freq)
            # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®One-Hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
            df_train = pd.get_dummies(df_train)
            df_test = pd.get_dummies(df_test)
            # ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®å®šç¾©ï¼ˆæ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ï¼‰
            X_train = df_train.select_dtypes(include=[np.number]).drop(columns=[selected_variable])
            y_train = df_train[selected_variable]
            X_test = df_test.select_dtypes(include=[np.number]).drop(columns=[selected_variable])
            y_test = df_test[selected_variable]
            # æ¬ æå€¤ã‚’é™¤å»
            X_train = X_train.dropna()
            y_train = y_train.loc[X_train.index]  # X_trainã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã•ã›ã‚‹
            X_test = X_test.dropna()
            y_test = y_test.loc[X_test.index]
            # ç‰¹å¾´é‡é¸æŠ (RFECV)
            rfecv = RFECV(
                estimator=xgb.XGBRegressor(random_state=100),
                min_features_to_select=5,
                step=1,
                scoring="neg_mean_absolute_percentage_error"
            )
            rfecv.fit(X_train, y_train)
            selected_features = X_train.columns[rfecv.support_].tolist()
            st.write("é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡:", selected_features)#å®Œæˆå‰ã«æ¶ˆã™
            # ç‰¹å¾´é‡é¸æŠå¾Œã®ãƒ‡ãƒ¼ã‚¿
            X_train = X_train[selected_features]
            X_test = X_test[selected_features]
            # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆOptunaï¼‰
            def objective(trial):
                params = {
                    'n_estimators': trial.suggest_int('n_estimators', 50, 500),
                    'max_depth': trial.suggest_int('max_depth', 2, 10),
                    'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),
                    'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),
                    'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),
                    'gamma': trial.suggest_float('gamma', 0, 5),
                    'reg_alpha': trial.suggest_float('reg_alpha', 0, 5),
                    'reg_lambda': trial.suggest_float('reg_lambda', 0, 5),
                    'random_state': 100
                }
                model = xgb.XGBRegressor(**params)
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                return mean_absolute_percentage_error(y_test, y_pred)
            study = optuna.create_study(direction='minimize')
            study.optimize(objective, n_trials=50)
            # æœ€é©ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’
            best_params = study.best_params
            st.write("æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:", best_params)#å®Œæˆå‰ã«æ¶ˆã™

            # ä¸é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿å‹ã®åˆ—ã‚’å‰Šé™¤ã¾ãŸã¯å¤‰æ›
            def preprocess_features(df):
                """
                XGBoost ãƒ¢ãƒ‡ãƒ«ã«é©ã—ãŸãƒ‡ãƒ¼ã‚¿å‹ã«å¤‰æ›ã™ã‚‹é–¢æ•°ã€‚
                datetime64[ns] å‹ã‚„ object å‹ã®åˆ—ã‚’å‰Šé™¤ã¾ãŸã¯ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã—ã¾ã™ã€‚
                """
                # datetime å‹ã®åˆ—ã‚’å‰Šé™¤ã¾ãŸã¯æ•°å€¤ã«å¤‰æ›
                #if "yyyymmdd" in df.columns:
                    #df["year"] = df["yyyymmdd"].dt.year
                    #df["month"] = df["yyyymmdd"].dt.month
                    #df["day"] = df["yyyymmdd"].dt.day
                    #df["dayofweek"] = df["yyyymmdd"].dt.dayofweek
                    #df = df.drop(columns=["yyyymmdd"])  # å…ƒã®æ—¥ä»˜åˆ—ã‚’å‰Šé™¤

                # object å‹ã®åˆ—ã‚’ category å‹ã«å¤‰æ›
                for col in df.select_dtypes(include=["object"]).columns:
                    df[col] = df[col].astype("category").cat.codes  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ•°å€¤ã«å¤‰æ›

                return df

            # ç‰¹å¾´é‡ã‚’å‰å‡¦ç†
            #X_train = preprocess_features(X_train)
            #X_test = preprocess_features(X_test)

            # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            model = xgb.XGBRegressor(**best_params)
            model.fit(X_train, y_train)
            y_train_pred = train_pred = model.predict(X_train)

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
            y_pred = model.predict(X_test)

            # ãƒ‡ãƒ¼ã‚¿ã®é »åº¦ã«åŸºã¥ã„ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®äºˆæ¸¬æœŸé–“ã‚’è¨­å®š
            freq_map = {"æ—¥æ¬¡": "D", "æœˆæ¬¡": "M", "å¹´æ¬¡": "Y"}
            freq = freq_map.get(frequency, None)

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®äºˆæ¸¬æœŸé–“ã‚’è¨­å®š
            default_future_periods = {"D": 30, "M": 12, "Y": 5}  # æ—¥æ¬¡: 30æ—¥, æœˆæ¬¡: 12ãƒ¶æœˆ, å¹´æ¬¡: 5å¹´
            future_periods = default_future_periods.get(freq, 12)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœˆæ¬¡ã®12ãƒ¶æœˆ

            # ç‰¹å¾´é‡ã®æ•´åˆæ€§ã‚’ç¢ºä¿ã™ã‚‹é–¢æ•°
            def align_features(X_train, X_future):
                """
                å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã‚’æƒãˆã‚‹é–¢æ•°ã€‚
                """
                # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã—ãªã„åˆ—ã‚’äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤
                X_future = X_future[X_train.columns.intersection(X_future.columns)]

                # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ãŒäºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã«ãªã„åˆ—ã‚’è¿½åŠ ï¼ˆå€¤ã¯0ã§åŸ‹ã‚ã‚‹ï¼‰
                for col in X_train.columns:
                    if col not in X_future.columns:
                        X_future[col] = 0


                return X_future
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æœ€çµ‚æ—¥ä»˜ã‚’å–å¾—
            last_date = df_test["yyyymmdd"].max()

            # é »åº¦ã«åŸºã¥ã„ã¦ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’è¨­å®š
            if freq == 'D':
                offset = pd.DateOffset(days=1)
            elif freq == 'M':
                offset = pd.DateOffset(months=1)
            elif freq == 'Y':
                offset = pd.DateOffset(years=1)
            else:
                raise ValueError("æ—¥æ¬¡ã€æœˆæ¬¡ã€å¹´æ¬¡ã®ã„ãšã‚Œã‹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚")

            # æœªæ¥ã®æ—¥ä»˜ã‚’ç”Ÿæˆ
            future_dates = pd.date_range(start=last_date + offset, periods=future_periods, freq=freq)
            st.write(f"æœªæ¥ã®æ—¥ä»˜: {future_dates}") 
            # future_df ã®ä½œæˆ
            future_df = pd.DataFrame({"yyyymmdd": pd.to_datetime(future_dates)})
            st.write(f"future_df: {future_df}")  # future_df ã®å†…å®¹ã‚’è¡¨ç¤º

            # æœªæ¥ãƒ‡ãƒ¼ã‚¿ã«ã‚‚ç‰¹å¾´é‡ç”Ÿæˆ
            future_df = create_time_features(future_df.copy(), selected_variable, freq)

            # one-hot encodingï¼ˆå¿…è¦ãªã‚‰ï¼‰
            future_df = pd.get_dummies(future_df)
            st.write(f"future_df after one-hot encoding: {future_df}")  # one-hot encoding å¾Œã® future_df ã‚’è¡¨ç¤º
            # äºˆæ¸¬ã«å¿…è¦ãªç‰¹å¾´é‡ã«æ•´å½¢
            X_future = future_df.select_dtypes(include=[np.number])
            X_future = align_features(X_train, X_future)
            X_future = X_future[X_train.columns]
            st.write(f"X_future: {X_future}")



            y_train_pred_update = y_train_pred.copy()
            test_pred = y_train_pred_update[-future_periods:]
            st.subheader("ğŸ“ˆ äºˆæ¸¬çµæœ")
            future_dates = [date.strftime('%Y-%m-%d') for date in future_dates]
            st.write(pd.DataFrame({
                "yyyymmdd": future_dates,
                "Predicted": test_pred
            }))


            # æ—¥ä»˜ã‚’æ•°å€¤ã«å¤‰æ›ï¼ˆä¾‹: å¹´æœˆæ—¥ã‚’æ•´æ•°ã«å¤‰æ›ï¼‰
            if "yyyymmdd" in future_df.columns:
                future_df["yyyymmdd"] = future_df["yyyymmdd"].apply(lambda x: x.toordinal())

            # äºˆæ¸¬çµæœã‚’å–å¾—
            train_pred = model.predict(X_train)
            test_pred = model.predict(X_test)

            # ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦äºˆæ¸¬åˆ—ã‚’è¿½åŠ 
            train_pred_df = X_train.copy()
            train_pred_df[selected_variable] = train_pred

            test_pred_df = X_test.copy()
            test_pred_df[selected_variable] = test_pred

 

            
            
      






            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã¨ç‰¹å¾´é‡ã‚’åˆ†ã‘ã‚‹
            X_train_pred = train_pred_df.drop(columns=[selected_variable])
            y_train_pred = train_pred_df[selected_variable]

            X_test_pred = test_pred_df.drop(columns=[selected_variable])
            y_test_pred = test_pred_df[selected_variable]

            X_train_pred_new = X_train_pred[selected_features]
            X_test_pred_new = X_test_pred[selected_features]


             # y_train_pred ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦æ›´æ–°ç”¨ã«ä½¿ã†
            y_train_pred_update = y_train_pred.copy()



            # äºˆæ¸¬ãƒ«ãƒ¼ãƒ—ï¼ˆX_test_pred_newã®è¡Œæ•°åˆ†ã ã‘äºˆæ¸¬ã‚’ç¹°ã‚Šè¿”ã™ï¼‰
            for i in range(len(y_test_pred)):
                # 1ã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬
                X_value_pred = X_test_pred_new.iloc[i:(i+1), :]
                y_value_pred = model.predict(X_value_pred)
                y_value_pred = pd.Series(y_value_pred, index=[X_value_pred.index[0]])

                # äºˆæ¸¬çµæœã‚’ç´¯ç©
                y_train_pred_update = pd.concat([y_train_pred_update, y_value_pred])

                # ç‰¹å¾´é‡ã®æ›´æ–°ï¼ˆæœ€æ–°ã® y_train_pred_update ã‚’ã‚‚ã¨ã«è¨ˆç®—ï¼‰
                lag1_cancel_user_new = y_train_pred_update.iloc[-1]
                _12week_lag7_moving_avg_new = np.mean([y_train_pred_update.iloc[-7 * j] for j in range(1, 13)])  # -7, -14, ..., -84
                _14days_fibonacci_retracement_236upper_new = y_train_pred_update.iloc[-14:].max() - (
                    y_train_pred_update.iloc[-14:].max() - y_train_pred_update.iloc[-14:].min()
                ) * 0.236
                macd_short_new = np.log10(abs(y_train_pred_update) + 1.0).ewm(span=7).mean().iloc[-1] - np.log10(
                    abs(y_train_pred_update) + 1.0
                ).ewm(span=30).mean().iloc[-1]
                _8week_lag7_moving_avg_new = np.mean([y_train_pred_update.iloc[-7 * j] for j in range(1, 9)])  # -7, -14, ..., -56
                _7days_moving_sum_new = y_train_pred_update.iloc[-7:].sum()
                _14days_fibonacci_retracement_236under_new = y_train_pred_update.iloc[-14:].min() + (
                    y_train_pred_update.iloc[-14:].max() - y_train_pred_update.iloc[-14:].min()
                ) * 0.236

                # ç‰¹å¾´é‡ã‚’ X_test_pred_new ã®æ¬¡ã®è¡Œã«åæ˜ 
                # ç‰¹å¾´é‡ã®æ›´æ–°
                for feature, new_value in zip(
                    selected_features,
                    [
                        lag1_cancel_user_new,
                        _12week_lag7_moving_avg_new,
                        _14days_fibonacci_retracement_236upper_new,
                        macd_short_new,
                        _8week_lag7_moving_avg_new,
                        _7days_moving_sum_new,
                        _14days_fibonacci_retracement_236under_new
                    ]
                ):
                    if (i + 1) < len(X_test_pred_new) and feature in X_test_pred_new.columns:
                        X_test_pred_new.iloc[i + 1, X_test_pred_new.columns.get_loc(feature)] = new_value
                # æœ€çµ‚äºˆæ¸¬çµæœï¼ˆç›´è¿‘35å€‹ï¼‰
                forecast = y_train_pred_update[-30:]

                print(forecast)
                df["yyyymmdd"] = pd.to_datetime(df["yyyymmdd"]).dt.normalize()
                test_start = pd.to_datetime(test_start).normalize()
                test_end = pd.to_datetime(test_end).normalize()

                st.subheader("ğŸ“ˆ äºˆæ¸¬çµæœ")
                st.write(pd.DataFrame({
                    "yyyymmdd": future_dates,
                    "Predicted": forecast.values
                }))

                st.write(f"future_dates: {len(future_dates)} ä»¶")
                st.write(f"y_pred_future: {len(forecast.values)} ä»¶")


            # è¡¨ç¤º
            st.subheader("ğŸ“ˆ äºˆæ¸¬çµæœ")
            st.write(pd.DataFrame({"yyyymmdd": future_dates, "Predicted": forecast}))

            # ã‚°ãƒ©ãƒ•ã®æç”»
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(future_dates, forecast, label="Forecast", marker="x")
            plt.xticks(rotation=45)
            plt.legend()
            st.pyplot(fig)

            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
            st.download_button(
                label="ğŸ“¥ äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=pd.DataFrame({"yyyymmdd": future_dates, "Predicted": forecast}).to_csv(index=False).encode("utf-8"),
                file_name="forecast_results.csv",
                mime="text/csv",
            )

            # äºˆæ¸¬çµæœã‚’è¡¨ç¤º
            st.subheader(f"ğŸ“ˆ {selected_variable} ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æœŸé–“ã®äºˆå®Ÿãƒ—ãƒ­ãƒƒãƒˆ")
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(df_test["yyyymmdd"], y_test, label="Actual", marker="o")
            ax.plot(df_test["yyyymmdd"], y_pred, label="Predicted", marker="x")
            plt.xticks(rotation=45)
            plt.legend()
            st.pyplot(fig)
            st.write(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ—¥æ•°: {len(df_test)}")
            st.write("ğŸ“… test_start:", test_start)
            st.write("ğŸ“… test_end:", test_end)
            st.write("ğŸ§ª df_test ã®è¡Œæ•°:", len(df_test))
            st.write(df_test.head())
            filtered = df[(df["yyyymmdd"] >= test_start) & (df["yyyymmdd"] <= test_end)]
            st.write("ğŸ” ãƒ•ã‚£ãƒ«ã‚¿çµæœ", filtered)






            # MAPE ã®è¨ˆç®—
            mape = mean_absolute_percentage_error(y_test, y_pred)
            st.write(f"âœ… **MAPE**: {mape:.2f} %")
            # MAPE ã«åŸºã¥ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
            if mape <= 8.5:
                st.success("âœ… ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ãƒœã‚¿ãƒ³ã‚ˆã‚Šäºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãã ã•ã„ã€‚")
                df_result = df_test[["yyyymmdd"]].copy()
                df_result["Actual"] = y_test.values
                df_result["Predicted"] = y_pred
                csv = df_result.to_csv(index=False).encode("utf-8")
                st.download_button(
                    label="ğŸ“¥ äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv,
                    file_name="prediction_results.csv",
                    mime="text/csv",
                )
            else:
                st.error("âš ï¸ ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")


# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒœã‚¿ãƒ³ã‚’è¨­ç½®
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "show_qa" not in st.session_state:
    st.session_state["show_qa"] = False  # åˆæœŸå€¤ã‚’ False ã«è¨­å®š

with st.sidebar:
    if st.button("Q&A"):
        st.session_state["show_qa"] = not st.session_state["show_qa"]

    # Q&Aã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤ºï¼ˆãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã¨ãã ã‘ï¼‰
    if st.session_state["show_qa"]:
        st.write("### ã‚ˆãã‚ã‚‹è³ªå•")
        st.write("**Q1: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã®æœŸé–“ã®ç›®å®‰ã¯ï¼Ÿ**")
        st.write("A1: æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆæœ€ä½ã§ã‚‚ 3å¹´åˆ†ã€å¹´æ¬¡ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯æœ€ä½ã§ã‚‚ 20å¹´åˆ†ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
        
        st.write("**Q2: äºˆæ¸¬æœŸé–“ã¯ï¼Ÿ**")
        st.write("A2: æ—¥æ¬¡ã®å ´åˆã¯30æ—¥ã€æœˆæ¬¡ã®å ´åˆã¯12ãƒ¶æœˆã€å¹´æ¬¡ã®å ´åˆã¯5å¹´ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¨­å®šã—ã¦ã„ã¾ã™ã€‚")
        
        st.write("**Q3: ãŠå•ã„åˆã‚ã›æ–¹æ³•ã¯ï¼Ÿ**")
        st.write("A3: æ“ä½œæ–¹æ³•ãŒã‚ã‹ã‚‰ãªã„ã€æ­£ã—ãæ“ä½œã—ã¦ã„ã‚‹ã¯ãšãªã®ã«ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹ã€ãƒ¢ãƒ‡ãƒ«ç²¾åº¦ãŒã©ã†ã—ã¦ã‚‚å‡ºãªã„ãªã©ã€è³ªå•ãƒ»ã”ç›¸è«‡ãŒã‚ã‚‹æ–¹ã¯ä»¥ä¸‹é€£çµ¡å…ˆã«çŠ¶æ³ã‚’ã”é€£çµ¡ãã ã•ã„ã€‚æ‹…å½“è€…ã‚ˆã‚Šè¿”ä¿¡ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚<br>å•ã„åˆã‚ã›å…ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼šcontact@b-mystory.com<br>æ‹…å½“ï¼šä½œç”°ã€é‡æœ¬", unsafe_allow_html=True)


